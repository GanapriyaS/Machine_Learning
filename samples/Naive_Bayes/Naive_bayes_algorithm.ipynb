{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo4Kxmz_c7PE"
   },
   "source": [
    "# **SKLEARN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suvL1kxj33Ob",
    "outputId": "9f143ac6-c406-4085-d429-0af465f4d707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances of the dataset: 33\n",
      "The message and its label of first 5 instances are listed below\n",
      "This is a nice restaurant , pos\n",
      "I wrote the test well , pos\n",
      "I love playing , pos\n",
      "This is a good painting , pos\n",
      "I did a good thing , pos\n",
      "Dataset is split into Training and Testing samples\n",
      "the total number of Training Data : 24\n",
      "the total number of Test Data : 9\n",
      "Total features extracted using CountVectorizer: 40\n",
      "Features for first 5 training instances are listed below\n",
      "   am  amazing  an  anything  are  being  cannot  care  did  do  ...  she  \\\n",
      "0   0        0   0         0    0      0       0     0    0   0  ...    0   \n",
      "1   1        0   0         0    0      0       0     0    0   0  ...    0   \n",
      "2   0        0   0         0    0      0       0     0    1   0  ...    0   \n",
      "3   0        0   0         0    0      0       0     0    0   0  ...    0   \n",
      "4   0        0   1         0    1      0       0     0    0   0  ...    0   \n",
      "\n",
      "   still  talking  thing  this  to  well  what  why  you  \n",
      "0      0        0      0     1   0     0     0    0    0  \n",
      "1      0        0      0     0   0     0     0    0    0  \n",
      "2      0        0      1     0   0     0     0    0    0  \n",
      "3      0        0      0     1   0     0     0    0    0  \n",
      "4      0        1      0     0   0     0     0    1    1  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "Classification results of testing samples are given below\n",
      "I dont care what you say-> neg\n",
      "I hate doing this-> neg\n",
      "she is an amazing person-> pos\n",
      "You have a nice handwriting-> pos\n",
      "I wrote the test well-> pos\n",
      "I cannot do this-> neg\n",
      "I hate being still-> neg\n",
      "I wrote the test well-> pos\n",
      "I love playing-> pos\n",
      "Accuracy metrics\n",
      "Accuracy of the classifier is 1.0\n",
      "The value of Precision 1.0\n",
      "The value of Recall 1.0\n",
      "Confusion matrix\n",
      "[[4 0]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "msg=pd.read_csv('data.csv',names=['message','label'])\n",
    "print('Total instances of the dataset:',msg.shape[0])\n",
    "msg['labelnum']=msg.label.map({'pos':1,'neg':0})\n",
    "X=msg.message\n",
    "Y=msg.labelnum\n",
    "print('The message and its label of first 5 instances are listed below')\n",
    "X5, Y5 =X[0:5], msg.label[0:5]\n",
    "for x, y in zip(X5,Y5):\n",
    "  print(x, ',', y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X, Y)\n",
    "print('Dataset is split into Training and Testing samples')\n",
    "print ('the total number of Training Data :',xtrain.shape[0])\n",
    "print ('the total number of Test Data :',xtest.shape[0])\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "xtrain_dtm = cv.fit_transform(xtrain)\n",
    "xtest_dtm=cv.transform(xtest)\n",
    "print('Total features extracted using CountVectorizer:',xtrain_dtm.shape[1])\n",
    "print('Features for first 5 training instances are listed below')\n",
    "df=pd.DataFrame(xtrain_dtm.toarray(),columns=cv.get_feature_names())\n",
    "print(df[0:5])\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(xtrain_dtm, ytrain)\n",
    "predicted = clf.predict(xtest_dtm)\n",
    "print('Classification results of testing samples are given below')\n",
    "for doc,p in zip(xtest, predicted):\n",
    "  pred = 'pos' if p==1 else 'neg'\n",
    "  print('%s-> %s'%(doc,pred))\n",
    "from sklearn import metrics\n",
    "print('Accuracy metrics')\n",
    "print('Accuracy of the classifier is',metrics.accuracy_score(ytest,predicted))\n",
    "print('The value of Precision', metrics.precision_score(ytest,predicted))\n",
    "print('The value of Recall', metrics.recall_score(ytest,predicted))\n",
    "print('Confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgduEgoLchhU"
   },
   "source": [
    "# **GAUSSIAN NAIVE BAYES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnMckY-GDCd8"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "Step 1: Separate By Class.\n",
    "Step 2: Summarize Dataset.\n",
    "Step 3: Summarize Data By Class.\n",
    "Step 4: Gaussian Probability Density Function.\n",
    "Step 5: Class Probabilities.\n",
    "\n",
    "\t\tBayes Theorem:\n",
    "\t\t\t\t\t\t\t\t\t\t              Likelihood * Class prior probability\n",
    "\t\t\t\tPosterior Probability = -------------------------------------\n",
    "\t\t\t\t\t\t\t\t\t\t\t                  Predictor prior probability\n",
    "\t\t\t\t\n",
    "\t\t\t\t\t\t\t  \t\t\t       P(x|c) * p(c)\n",
    "\t\t\t\t\t\t\t   P(c|x) = ------------------ \n",
    "\t\t\t\t\t\t\t\t\t\t\t            P(x)\n",
    "\t\tGaussian Naive Bayes:\n",
    "\t\t\t\t\t\t\t         1\t\t\t\t\t\t\t\t\n",
    "\t\t\t\tP(x|c) = --------------------------- * exp(- (x - mean)^2 / 2*(var(x)^2)))\n",
    "\t\t\t\t\t\t   sqrt(2 * pi * var(x)^2)\n",
    "```\n",
    "Bayes’ Theorem is stated as:\n",
    "\n",
    "P(class|data) = (P(data|class) * P(class)) / P(data)\n",
    "Where P(class|data) is the probability of class given the provided data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1vM2KI74N6W"
   },
   "source": [
    "[Reference for scratch implementation](https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7qmKzatURjDy"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from math import pi\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wW1DVRlOQCRv"
   },
   "source": [
    "**Step 1: Separate By Class.**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qKwJAjqFLNs-"
   },
   "outputs": [],
   "source": [
    "def separate_by_class(dataset):\n",
    "\tseparated = dict()\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tvector = dataset[i]\n",
    "\t\tclass_value = vector[-1]\n",
    "\t\tif (class_value not in separated):\n",
    "\t\t\tseparated[class_value] = list()\n",
    "\t\tseparated[class_value].append(vector)\n",
    "\treturn separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7i1ZpekFN2M2",
    "outputId": "ac02734e-0c46-4eaf-fdce-a339cfd2dfa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[3.393533211, 2.331273381, 0]\n",
      "[3.110073483, 1.781539638, 0]\n",
      "[1.343808831, 3.368360954, 0]\n",
      "[3.582294042, 4.67917911, 0]\n",
      "[2.280362439, 2.866990263, 0]\n",
      "1\n",
      "[7.423436942, 4.696522875, 1]\n",
      "[5.745051997, 3.533989803, 1]\n",
      "[9.172168622, 2.511101045, 1]\n",
      "[7.792783481, 3.424088941, 1]\n",
      "[7.939820817, 0.791637231, 1]\n"
     ]
    }
   ],
   "source": [
    "dataset = [[3.393533211,2.331273381,0],\n",
    "\t[3.110073483,1.781539638,0],\n",
    "\t[1.343808831,3.368360954,0],\n",
    "\t[3.582294042,4.67917911,0],\n",
    "\t[2.280362439,2.866990263,0],\n",
    "\t[7.423436942,4.696522875,1],\n",
    "\t[5.745051997,3.533989803,1],\n",
    "\t[9.172168622,2.511101045,1],\n",
    "\t[7.792783481,3.424088941,1],\n",
    "\t[7.939820817,0.791637231,1]]\n",
    "separated = separate_by_class(dataset)\n",
    "for label in separated:\n",
    "\tprint(label)\n",
    "\tfor row in separated[label]:\n",
    "\t\tprint(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q23mK3qjQP9N"
   },
   "source": [
    "**Step 2: Summarize Dataset**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7rZwYPsGOAi9"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# Calculate the mean of a list of numbers\n",
    "def mean(numbers):\n",
    "\treturn sum(numbers)/float(len(numbers))\n",
    "\n",
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers):\n",
    "\tavg = mean(numbers)\n",
    "\tvariance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
    "\treturn sqrt(variance)\n",
    "\n",
    "# Calculate the mean, stdev and count for each column in a dataset\n",
    "def summarize_dataset(dataset):\n",
    "\tsummaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
    "\tdel(summaries[-1])\n",
    "#  remove the statistics for the class variable as we will not need these statistics\n",
    "\treturn summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HDqnLT2HOGVN",
    "outputId": "79237cf5-8391-4d27-933e-7dc60d42ff01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5.178333386499999, 2.7665845055177263, 10), (2.9984683241, 1.218556343617447, 10)]\n"
     ]
    }
   ],
   "source": [
    "dataset = [[3.393533211,2.331273381,0],\n",
    "\t[3.110073483,1.781539638,0],\n",
    "\t[1.343808831,3.368360954,0],\n",
    "\t[3.582294042,4.67917911,0],\n",
    "\t[2.280362439,2.866990263,0],\n",
    "\t[7.423436942,4.696522875,1],\n",
    "\t[5.745051997,3.533989803,1],\n",
    "\t[9.172168622,2.511101045,1],\n",
    "\t[7.792783481,3.424088941,1],\n",
    "\t[7.939820817,0.791637231,1]]\n",
    "summary = summarize_dataset(dataset)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8MS8Xe2Qe1c"
   },
   "source": [
    "**Step 3: Summarize Data By Class.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7BCMrvcpOuo_"
   },
   "outputs": [],
   "source": [
    "# Split dataset by class then calculate statistics for each row\n",
    "def summarize_by_class(dataset):\n",
    "\tseparated = separate_by_class(dataset)\n",
    "\tsummaries = dict()\n",
    "\tfor class_value, rows in separated.items():\n",
    "\t\tsummaries[class_value] = summarize_dataset(rows)\n",
    "\treturn summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1z40k67tOuvz",
    "outputId": "5f0c5991-bd92-4309-b054-1445facf8ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(2.7420144012, 0.9265683289298018, 5)\n",
      "(3.0054686692, 1.1073295894898725, 5)\n",
      "1\n",
      "(7.6146523718, 1.2344321550313704, 5)\n",
      "(2.9914679790000003, 1.4541931384601618, 5)\n"
     ]
    }
   ],
   "source": [
    "# Test summarizing by class\n",
    "dataset = [[3.393533211,2.331273381,0],\n",
    "\t[3.110073483,1.781539638,0],\n",
    "\t[1.343808831,3.368360954,0],\n",
    "\t[3.582294042,4.67917911,0],\n",
    "\t[2.280362439,2.866990263,0],\n",
    "\t[7.423436942,4.696522875,1],\n",
    "\t[5.745051997,3.533989803,1],\n",
    "\t[9.172168622,2.511101045,1],\n",
    "\t[7.792783481,3.424088941,1],\n",
    "\t[7.939820817,0.791637231,1]]\n",
    "summary = summarize_by_class(dataset)\n",
    "for label in summary:\n",
    "\tprint(label)\n",
    "\tfor row in summary[label]:\n",
    "\t\tprint(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5eOBBVFQnwp"
   },
   "source": [
    "**Step 4: Gaussian Probability Density Function.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FZONQSHGQyqL"
   },
   "outputs": [],
   "source": [
    "def calculate_probability(x, mean, stdev):\n",
    "\texponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "\treturn (1 / (sqrt(2 * pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cV8gocoDQy-O",
    "outputId": "a392ce4c-204c-4c3d-b785-b7fb5f513254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3989422804014327\n",
      "0.24197072451914337\n",
      "0.24197072451914337\n"
     ]
    }
   ],
   "source": [
    "print(calculate_probability(1.0, 1.0, 1.0))\n",
    "print(calculate_probability(2.0, 1.0, 1.0))\n",
    "print(calculate_probability(0.0, 1.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ygTlyuvR-ZG"
   },
   "source": [
    "**Step 5: Class Probabilities.**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7GpyI99St1D"
   },
   "source": [
    "P(class=0|X1,X2) = P(X1|class=0) * P(X2|class=0) * P(class=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mJtt4U_8QzBc"
   },
   "outputs": [],
   "source": [
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "\ttotal_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "\tprobabilities = dict()\n",
    "\tfor class_value, class_summaries in summaries.items():\n",
    "\t\tprobabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "\t\tfor i in range(len(class_summaries)):\n",
    "\t\t\tmean, stdev, count = class_summaries[i]\n",
    "\t\t\tprobabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
    "\treturn probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7m9tgo3QzEl",
    "outputId": "0c7690c5-600a-493f-a61c-71ca5a0abf25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.05032427673372076, 1: 0.00011557718379945765}\n"
     ]
    }
   ],
   "source": [
    "dataset = [[3.393533211,2.331273381,0],\n",
    "\t[3.110073483,1.781539638,0],\n",
    "\t[1.343808831,3.368360954,0],\n",
    "\t[3.582294042,4.67917911,0],\n",
    "\t[2.280362439,2.866990263,0],\n",
    "\t[7.423436942,4.696522875,1],\n",
    "\t[5.745051997,3.533989803,1],\n",
    "\t[9.172168622,2.511101045,1],\n",
    "\t[7.792783481,3.424088941,1],\n",
    "\t[7.939820817,0.791637231,1]]\n",
    "summaries = summarize_by_class(dataset)\n",
    "probabilities = calculate_class_probabilities(summaries, dataset[0])\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "GxYIPUTo4Bh-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from random import seed,randrange\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "NbWdaoJSOFui"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1fQETCru5N8s"
   },
   "outputs": [],
   "source": [
    "def str_column_to_float(dataset,column):\n",
    "  for row in dataset:\n",
    "    if(isinstance(row[column],str)):\n",
    "      row[column]=float(row[column].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "oQvjeLW45wWY"
   },
   "outputs": [],
   "source": [
    "def str_column_to_int(dataset, column):\n",
    "\tclass_values = [row[column] for row in dataset]\n",
    "\tunique = set(class_values)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = lookup[row[column]]\n",
    "\treturn lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJ2Q1mQO4gFV",
    "outputId": "d9a47941-17bc-437e-dc8d-497b0c1f401d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.9, 3.0, 1.4, 0.2, 0]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('iris.csv')\n",
    "data=data.values.tolist()\n",
    "for i in range(len(data[0])-1):\n",
    "\tstr_column_to_float(data, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(data, len(data[0])-1)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "iXkkW-UY6c_E"
   },
   "outputs": [],
   "source": [
    "def accuracy_metric(actual,predicted):\n",
    "  correct=0\n",
    "  for i in range(len(actual)):\n",
    "    if actual[i]==predicted[i]:\n",
    "      correct+=1\n",
    "  print(confusion_matrix(actual,predicted))\n",
    "  print(classification_report(actual,predicted))\n",
    "  return correct/float(len(actual))*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_woeOC5x_gbM"
   },
   "outputs": [],
   "source": [
    "def cross_validation_split(data, folds=3):\n",
    "\tdataset_split = []\n",
    "\tdataset_copy = data\n",
    "\tfold_size = int(len(data) / folds)\n",
    "\tfor i in range(folds):\n",
    "\t\tfold = []\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "-5tDzpjy_-H_"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Predict the class for a given row\n",
    "def predict(summaries, row):\n",
    "\tprobabilities = calculate_class_probabilities(summaries, row)\n",
    "\tbest_label, best_prob = None, -1\n",
    "\tfor class_value, probability in probabilities.items():\n",
    "\t\tif best_label is None or probability > best_prob:\n",
    "\t\t\tbest_prob = probability\n",
    "\t\t\tbest_label = class_value\n",
    "\treturn best_label\n",
    " \n",
    "# Naive Bayes Algorithm\n",
    "def naive_bayes(train, test):\n",
    "\tsummarize = summarize_by_class(train)\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\toutput = predict(summarize, row)\n",
    "\t\tpredictions.append(output)\n",
    "\treturn(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "0_sNRzjZALmZ"
   },
   "outputs": [],
   "source": [
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = naive_bayes(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5wgmA34Bv5z",
    "outputId": "330a2e40-85f7-4e2e-d465-4735a7b1998c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        29\n",
      "   macro avg       1.00      1.00      1.00        29\n",
      "weighted avg       1.00      1.00      1.00        29\n",
      "\n",
      "[[ 9  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        29\n",
      "   macro avg       1.00      1.00      1.00        29\n",
      "weighted avg       1.00      1.00      1.00        29\n",
      "\n",
      "[[ 9  0  0]\n",
      " [ 0 10  2]\n",
      " [ 0  2  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.83      0.83      0.83        12\n",
      "           2       0.75      0.75      0.75         8\n",
      "\n",
      "    accuracy                           0.86        29\n",
      "   macro avg       0.86      0.86      0.86        29\n",
      "weighted avg       0.86      0.86      0.86        29\n",
      "\n",
      "[[ 6  0  0]\n",
      " [ 0  6  2]\n",
      " [ 0  1 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       0.86      0.75      0.80         8\n",
      "           2       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.90        29\n",
      "   macro avg       0.91      0.89      0.90        29\n",
      "weighted avg       0.90      0.90      0.89        29\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0  8  0]\n",
      " [ 0  1  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       0.89      1.00      0.94         8\n",
      "           2       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.97        29\n",
      "   macro avg       0.96      0.97      0.96        29\n",
      "weighted avg       0.97      0.97      0.97        29\n",
      "\n",
      "Scores: [100.0, 100.0, 86.20689655172413, 89.65517241379311, 96.55172413793103]\n",
      "Mean Accuracy: 94.483%\n"
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "scores = evaluate_algorithm(data,naive_bayes, n_folds)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptrXkilEZM6p",
    "outputId": "ff95bbc6-ffcc-442f-a92a-0f2dbc1be2ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data=[5.7, 2.9, 4.2, 1.3], Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "model = summarize_by_class(dataset)\n",
    "# define a new record\n",
    "row = [5.7,2.9,4.2,1.3]\n",
    "# predict the label\n",
    "label = predict(model, row)\n",
    "print('Data=%s, Predicted: %s' % (row, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "csevuoO5cs74"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUoRvESpcvPT"
   },
   "source": [
    "# **BINOMIAL NAIVE BAYES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDfM3rsCdrmJ"
   },
   "source": [
    "```\n",
    "Bayes Theorem:\n",
    "\t\t\t\t\t\t\t\t\t\t              Likelihood * Class prior probability\n",
    "\t\t\t\tPosterior Probability = -------------------------------------\n",
    "\t\t\t\t\t\t\t\t\t\t\t                Predictor prior probability\n",
    "\t\t\t\t\n",
    "\t\t\t\t\t\t\t  \t\t\t     P(x|c) * p(c)\n",
    "\t\t\t\t\t\t\t   P(c|x) = ------------------ \n",
    "\t\t\t\t\t\t\t\t\t\t\t          P(x)\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "1BYmrjnwopZE"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('iris.csv')\n",
    "data=data.values.tolist()\n",
    "for i in range(len(data[0])-1):\n",
    "\tstr_column_to_float(data, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(data, len(data[0])-1)\n",
    "\n",
    "dataset=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5r2oP6nrc1kN",
    "outputId": "f7e1f80e-3695-4955-b6cb-90f01414305d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total yes: 9 / 14\n",
      "for feature 1\n",
      "3 / 0\n",
      "for feature 2\n",
      "0 / 0\n",
      "for feature 3\n",
      "3 / 0\n",
      "for feature 4\n",
      "6 / 0\n",
      "Total no: 5 / 14\n",
      "for feature 1\n",
      "2 / 0\n",
      "for feature 2\n",
      "0 / 0\n",
      "for feature 3\n",
      "4 / 0\n",
      "for feature 4\n",
      "2 / 0\n",
      "0.010973936899862825\n",
      "0.0024495394865765236\n",
      "Probability of playing golf: 81.75182481751824%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dataset = [\n",
    "           [0,0,1,0,0],\n",
    "           [0,0,1,1,0],\n",
    "           [1,0,1,0,1],\n",
    "           [2,1,1,0,1],\n",
    "           [2,2,0,0,1],\n",
    "           [2,2,0,1,0],\n",
    "           [1,2,0,1,1],\n",
    "           [0,1,1,0,0],\n",
    "           [0,2,0,0,1],\n",
    "           [2,1,0,0,1],\n",
    "           [0,1,0,1,1],\n",
    "           [1,1,1,1,1],\n",
    "           [1,0,0,0,1],\n",
    "           [2,1,1,1,0]\n",
    "           ]\n",
    "mp = dict()\n",
    "for i in range(len(dataset)):\n",
    "    row = dataset[i]\n",
    "    y = row[-1]\n",
    "    if (y not in mp):\n",
    "        mp[y] = list()\n",
    "    mp[y].append(row)\n",
    "\n",
    "test = [2,3,1,0]\n",
    "\n",
    "probYes = 1\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "for row in dataset:\n",
    "    if(row[-1] == 1):\n",
    "        count+=1\n",
    "    total+=1\n",
    "print(\"Total yes: \"+str(count)+\" / \"+str(total))\n",
    "probYes = count/total\n",
    "l=[]\n",
    "for i in range(len(test)):\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for row in mp[1]:\n",
    "        if(test[i] == row[i]):\n",
    "            count += 1\n",
    "    l.append(count)\n",
    "\n",
    "    print('for feature '+str(i+1))\n",
    "    print(str(count)+\" / \"+str(total))\n",
    "  \n",
    "ll=[i+1 for i in l if 0 in l]\n",
    "\n",
    "for i in ll:\n",
    "  probYes *= i/len(mp[1])\n",
    "\n",
    "probNo = 1\n",
    "count = 0\n",
    "total = 0\n",
    "for row in dataset:\n",
    "    if(row[-1] == 0):\n",
    "        count+=1\n",
    "    total+=1\n",
    "probNo = count/total\n",
    "print(\"Total no: \"+str(count)+\" / \"+str(total))\n",
    "# for i in range(len(test)):\n",
    "#     count = 0\n",
    "#     total = 0\n",
    "#     for row in mp[0]:\n",
    "#         if(test[i] == row[i]):\n",
    "#             count += 1\n",
    "#         total += 1\n",
    "#     print('for feature '+str(i+1))\n",
    "#     print(str(count)+\" / \"+str(total))\n",
    "#     probNo *= count/total\n",
    "\n",
    "l=[]\n",
    "for i in range(len(test)):\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for row in mp[0]:\n",
    "        if(test[i] == row[i]):\n",
    "            count += 1\n",
    "    l.append(count)\n",
    "\n",
    "    print('for feature '+str(i+1))\n",
    "    print(str(count)+\" / \"+str(total))\n",
    "  \n",
    "ll=[i+1 for i in l if 0 in l]\n",
    "\n",
    "for i in ll:\n",
    "  probNo *= i/len(mp[1])\n",
    "\n",
    "print(probYes)\n",
    "print(probNo)\n",
    "\n",
    "prob = probYes/(probYes+probNo)\n",
    "print(\"Probability of playing golf: \"+str(prob*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "1IvYXygSdair"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMY9P0l4ZRQb"
   },
   "source": [
    "# **BINOMIAL NAIVE BAYES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekkkbopDZRQr"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\t\tBayes Theorem:\n",
    "\t\t\t\t\t\t\t\t\t\t              Likelihood * Class prior probability\n",
    "\t\t\t\tPosterior Probability = -------------------------------------\n",
    "\t\t\t\t\t\t\t\t\t\t\t                  Predictor prior probability\n",
    "\t\t\t\t\n",
    "\t\t\t\t\t\t\t  \t\t\t       P(x|c) * p(c)\n",
    "\t\t\t\t\t\t\t   P(c|x) = ------------------ \n",
    "\t\t\t\t\t\t\t\t\t\t\t            P(x)\n",
    "```\n",
    "Bayes’ Theorem is stated as:\n",
    "\n",
    "P(class|data) = (P(data|class) * P(class)) / P(data)\n",
    "Where P(class|data) is the probability of class given the provided data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XEnJLaEZRQy"
   },
   "source": [
    "P(class=0|X1,X2) = P(X1|class=0) * P(X2|class=0) * P(class=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "GDixYdamak0D"
   },
   "outputs": [],
   "source": [
    "def separated_by_class(dataset):\n",
    "\tseparated = dict()\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tvector = dataset[i]\n",
    "\t\tclass_value = vector[-1]\n",
    "\t\tif (class_value not in separated):\n",
    "\t\t\tseparated[class_value] = list()\n",
    "\t\tseparated[class_value].append(vector)\n",
    "\treturn separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "V7MOFhO4eOCP"
   },
   "outputs": [],
   "source": [
    "def calculate_class_probabilities(dataset,summaries,row):\n",
    "  for label in summaries:\n",
    "    prob=1\n",
    "    prob = len(summaries[label])/len(dataset)\n",
    "    labl=0\n",
    "    value=0\n",
    "    likehood=[]\n",
    "    for i in range(len(row)-1):\n",
    "      count=0\n",
    "      for r in summaries[label]:\n",
    "        if(r[i]==row[i]):\n",
    "          count+=1\n",
    "        likehood.append(count)\n",
    "      # print(f'for feature {i} {count}/{len(summaries[label])}')\n",
    "    likehood_update=[i+1 for i in likehood if 0 in likehood]\n",
    "    if 0 in likehood:\n",
    "      for i in likehood_update:\n",
    "        prob*=i/(len(summaries[label]))\n",
    "    else:\n",
    "      for i in likehood_update:\n",
    "        prob*=i/sum(likehood_update)\n",
    "    if(prob>value):\n",
    "\n",
    "      value=prob\n",
    "      labl=label\n",
    "  \n",
    "  return labl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Mc7zMhfhZRQ0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from random import seed,randrange\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "sP1C8cVaZRQ0"
   },
   "outputs": [],
   "source": [
    "def str_column_to_float(dataset,column):\n",
    "  for row in dataset:\n",
    "    if(isinstance(row[column],str)):\n",
    "      row[column]=float(row[column].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Gvr2jmXbZRQ1"
   },
   "outputs": [],
   "source": [
    "def str_column_to_int(dataset, column):\n",
    "\tclass_values = [row[column] for row in dataset]\n",
    "\tunique = set(class_values)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = lookup[row[column]]\n",
    "\treturn lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "WWntHAynZRQ1"
   },
   "outputs": [],
   "source": [
    "data=[\n",
    "           [0,0,1,0,0],\n",
    "           [0,0,1,1,0],\n",
    "           [1,0,1,0,1],\n",
    "           [2,1,1,0,1],\n",
    "           [2,2,0,0,1],\n",
    "           [2,2,0,1,0],\n",
    "           [1,2,0,1,1],\n",
    "           [0,1,1,0,0],\n",
    "           [0,2,0,0,1],\n",
    "           [2,1,0,0,1],\n",
    "           [0,1,0,1,1],\n",
    "           [1,1,1,1,1],\n",
    "           [1,0,0,0,1],\n",
    "           [2,1,1,1,0]\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "CplaalVrZRQ2"
   },
   "outputs": [],
   "source": [
    "def accuracy_metric(actual,predicted):\n",
    "  print(actual,\"---------------\\n\",predicted)\n",
    "  correct=0\n",
    "  for i in range(len(actual)):\n",
    "    if actual[i]==predicted[i]:\n",
    "      correct+=1\n",
    "  # print(confusion_matrix(actual,predicted))\n",
    "  # print(classification_report(actual,predicted))\n",
    "  return correct/float(len(actual))*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "-a_NYd0wZRQ3"
   },
   "outputs": [],
   "source": [
    "def cross_validation_split(data, folds=3):\n",
    "\tdataset_split = []\n",
    "\tdataset_copy = data\n",
    "\tfold_size = int(len(data) / folds)\n",
    "\tfor i in range(folds):\n",
    "\t\tfold = []\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "SgnhEs8ZZRQ4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Naive Bayes Algorithm\n",
    "def naive_bayes(train, test):\n",
    "\tsummarize = separated_by_class(train)\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\toutput = calculate_class_probabilities(train,summarize, row)\n",
    "\t\tpredictions.append(output)\n",
    "\treturn(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "i0gZJzyBZRQ4"
   },
   "outputs": [],
   "source": [
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tprint(dataset)\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\t# row_copy[-1] = None\n",
    "\t\tprint(train_set)\n",
    "\t\tprint(test_set)\n",
    "\t\tpredicted = naive_bayes(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KP-8S-CZRQ4",
    "outputId": "1e174f60-608a-4e66-d03a-7d1239cd68d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.9, 3.0, 1.4, 0.2, 0], [4.7, 3.2, 1.3, 0.2, 0], [4.6, 3.1, 1.5, 0.2, 0], [5.0, 3.6, 1.4, 0.2, 0], [5.4, 3.9, 1.7, 0.4, 0], [4.6, 3.4, 1.4, 0.3, 0], [5.0, 3.4, 1.5, 0.2, 0], [4.4, 2.9, 1.4, 0.2, 0], [4.9, 3.1, 1.5, 0.1, 0], [5.4, 3.7, 1.5, 0.2, 0], [4.8, 3.4, 1.6, 0.2, 0], [4.8, 3.0, 1.4, 0.1, 0], [4.3, 3.0, 1.1, 0.1, 0], [5.8, 4.0, 1.2, 0.2, 0], [5.7, 4.4, 1.5, 0.4, 0], [5.4, 3.9, 1.3, 0.4, 0], [5.1, 3.5, 1.4, 0.3, 0], [5.7, 3.8, 1.7, 0.3, 0], [5.1, 3.8, 1.5, 0.3, 0], [5.4, 3.4, 1.7, 0.2, 0], [5.1, 3.7, 1.5, 0.4, 0], [4.6, 3.6, 1.0, 0.2, 0], [5.1, 3.3, 1.7, 0.5, 0], [4.8, 3.4, 1.9, 0.2, 0], [5.0, 3.0, 1.6, 0.2, 0], [5.0, 3.4, 1.6, 0.4, 0], [5.2, 3.5, 1.5, 0.2, 0], [5.2, 3.4, 1.4, 0.2, 0], [4.7, 3.2, 1.6, 0.2, 0], [4.8, 3.1, 1.6, 0.2, 0], [5.4, 3.4, 1.5, 0.4, 0], [5.2, 4.1, 1.5, 0.1, 0], [5.5, 4.2, 1.4, 0.2, 0], [4.9, 3.1, 1.5, 0.1, 0], [5.0, 3.2, 1.2, 0.2, 0], [5.5, 3.5, 1.3, 0.2, 0], [4.9, 3.1, 1.5, 0.1, 0], [4.4, 3.0, 1.3, 0.2, 0], [5.1, 3.4, 1.5, 0.2, 0], [5.0, 3.5, 1.3, 0.3, 0], [4.5, 2.3, 1.3, 0.3, 0], [4.4, 3.2, 1.3, 0.2, 0], [5.0, 3.5, 1.6, 0.6, 0], [5.1, 3.8, 1.9, 0.4, 0], [4.8, 3.0, 1.4, 0.3, 0], [5.1, 3.8, 1.6, 0.2, 0], [4.6, 3.2, 1.4, 0.2, 0], [5.3, 3.7, 1.5, 0.2, 0], [5.0, 3.3, 1.4, 0.2, 0], [7.0, 3.2, 4.7, 1.4, 1], [6.4, 3.2, 4.5, 1.5, 1], [6.9, 3.1, 4.9, 1.5, 1], [5.5, 2.3, 4.0, 1.3, 1], [6.5, 2.8, 4.6, 1.5, 1], [5.7, 2.8, 4.5, 1.3, 1], [6.3, 3.3, 4.7, 1.6, 1], [4.9, 2.4, 3.3, 1.0, 1], [6.6, 2.9, 4.6, 1.3, 1], [5.2, 2.7, 3.9, 1.4, 1], [5.0, 2.0, 3.5, 1.0, 1], [5.9, 3.0, 4.2, 1.5, 1], [6.0, 2.2, 4.0, 1.0, 1], [6.1, 2.9, 4.7, 1.4, 1], [5.6, 2.9, 3.6, 1.3, 1], [6.7, 3.1, 4.4, 1.4, 1], [5.6, 3.0, 4.5, 1.5, 1], [5.8, 2.7, 4.1, 1.0, 1], [6.2, 2.2, 4.5, 1.5, 1], [5.6, 2.5, 3.9, 1.1, 1], [5.9, 3.2, 4.8, 1.8, 1], [6.1, 2.8, 4.0, 1.3, 1], [6.3, 2.5, 4.9, 1.5, 1], [6.1, 2.8, 4.7, 1.2, 1], [6.4, 2.9, 4.3, 1.3, 1], [6.6, 3.0, 4.4, 1.4, 1], [6.8, 2.8, 4.8, 1.4, 1], [6.7, 3.0, 5.0, 1.7, 1], [6.0, 2.9, 4.5, 1.5, 1], [5.7, 2.6, 3.5, 1.0, 1], [5.5, 2.4, 3.8, 1.1, 1], [5.5, 2.4, 3.7, 1.0, 1], [5.8, 2.7, 3.9, 1.2, 1], [6.0, 2.7, 5.1, 1.6, 1], [5.4, 3.0, 4.5, 1.5, 1], [6.0, 3.4, 4.5, 1.6, 1], [6.7, 3.1, 4.7, 1.5, 1], [6.3, 2.3, 4.4, 1.3, 1], [5.6, 3.0, 4.1, 1.3, 1], [5.5, 2.5, 4.0, 1.3, 1], [5.5, 2.6, 4.4, 1.2, 1], [6.1, 3.0, 4.6, 1.4, 1], [5.8, 2.6, 4.0, 1.2, 1], [5.0, 2.3, 3.3, 1.0, 1], [5.6, 2.7, 4.2, 1.3, 1], [5.7, 3.0, 4.2, 1.2, 1], [5.7, 2.9, 4.2, 1.3, 1], [6.2, 2.9, 4.3, 1.3, 1], [5.1, 2.5, 3.0, 1.1, 1], [5.7, 2.8, 4.1, 1.3, 1], [6.3, 3.3, 6.0, 2.5, 2], [5.8, 2.7, 5.1, 1.9, 2], [7.1, 3.0, 5.9, 2.1, 2], [6.3, 2.9, 5.6, 1.8, 2], [6.5, 3.0, 5.8, 2.2, 2], [7.6, 3.0, 6.6, 2.1, 2], [4.9, 2.5, 4.5, 1.7, 2], [7.3, 2.9, 6.3, 1.8, 2], [6.7, 2.5, 5.8, 1.8, 2], [7.2, 3.6, 6.1, 2.5, 2], [6.5, 3.2, 5.1, 2.0, 2], [6.4, 2.7, 5.3, 1.9, 2], [6.8, 3.0, 5.5, 2.1, 2], [5.7, 2.5, 5.0, 2.0, 2], [5.8, 2.8, 5.1, 2.4, 2], [6.4, 3.2, 5.3, 2.3, 2], [6.5, 3.0, 5.5, 1.8, 2], [7.7, 3.8, 6.7, 2.2, 2], [7.7, 2.6, 6.9, 2.3, 2], [6.0, 2.2, 5.0, 1.5, 2], [6.9, 3.2, 5.7, 2.3, 2], [5.6, 2.8, 4.9, 2.0, 2], [7.7, 2.8, 6.7, 2.0, 2], [6.3, 2.7, 4.9, 1.8, 2], [6.7, 3.3, 5.7, 2.1, 2], [7.2, 3.2, 6.0, 1.8, 2], [6.2, 2.8, 4.8, 1.8, 2], [6.1, 3.0, 4.9, 1.8, 2], [6.4, 2.8, 5.6, 2.1, 2], [7.2, 3.0, 5.8, 1.6, 2], [7.4, 2.8, 6.1, 1.9, 2], [7.9, 3.8, 6.4, 2.0, 2], [6.4, 2.8, 5.6, 2.2, 2], [6.3, 2.8, 5.1, 1.5, 2], [6.1, 2.6, 5.6, 1.4, 2], [7.7, 3.0, 6.1, 2.3, 2], [6.3, 3.4, 5.6, 2.4, 2], [6.4, 3.1, 5.5, 1.8, 2], [6.0, 3.0, 4.8, 1.8, 2], [6.9, 3.1, 5.4, 2.1, 2], [6.7, 3.1, 5.6, 2.4, 2], [6.9, 3.1, 5.1, 2.3, 2], [5.8, 2.7, 5.1, 1.9, 2], [6.8, 3.2, 5.9, 2.3, 2], [6.7, 3.3, 5.7, 2.5, 2], [6.7, 3.0, 5.2, 2.3, 2], [6.3, 2.5, 5.0, 1.9, 2], [6.5, 3.0, 5.2, 2.0, 2], [6.2, 3.4, 5.4, 2.3, 2], [5.9, 3.0, 5.1, 1.8, 2]]\n",
      "[[5.4, 3.9, 1.3, 0.4, 0], [5.4, 3.0, 4.5, 1.5, 1], [6.1, 2.8, 4.7, 1.2, 1], [5.1, 3.7, 1.5, 0.4, 0], [5.0, 3.5, 1.6, 0.6, 0], [5.8, 2.8, 5.1, 2.4, 2], [5.7, 3.0, 4.2, 1.2, 1], [6.9, 3.1, 4.9, 1.5, 1], [4.6, 3.2, 1.4, 0.2, 0], [7.9, 3.8, 6.4, 2.0, 2], [7.6, 3.0, 6.6, 2.1, 2], [5.1, 3.8, 1.9, 0.4, 0], [5.2, 4.1, 1.5, 0.1, 0], [6.9, 3.2, 5.7, 2.3, 2], [5.1, 3.8, 1.5, 0.3, 0], [6.3, 2.5, 5.0, 1.9, 2], [6.0, 3.4, 4.5, 1.6, 1], [5.8, 2.7, 5.1, 1.9, 2], [5.7, 2.6, 3.5, 1.0, 1], [5.5, 2.3, 4.0, 1.3, 1], [4.8, 3.4, 1.9, 0.2, 0], [7.3, 2.9, 6.3, 1.8, 2], [4.8, 3.4, 1.6, 0.2, 0], [5.5, 2.4, 3.8, 1.1, 1], [4.6, 3.6, 1.0, 0.2, 0], [6.7, 3.3, 5.7, 2.5, 2], [5.0, 3.0, 1.6, 0.2, 0], [4.9, 2.5, 4.5, 1.7, 2], [6.0, 2.7, 5.1, 1.6, 1], [6.0, 2.2, 5.0, 1.5, 2], [5.4, 3.4, 1.7, 0.2, 0], [7.4, 2.8, 6.1, 1.9, 2], [6.3, 2.3, 4.4, 1.3, 1], [4.5, 2.3, 1.3, 0.3, 0], [5.0, 3.6, 1.4, 0.2, 0], [5.5, 4.2, 1.4, 0.2, 0], [5.7, 3.8, 1.7, 0.3, 0], [6.3, 2.7, 4.9, 1.8, 2], [5.6, 3.0, 4.5, 1.5, 1], [7.7, 3.0, 6.1, 2.3, 2], [6.1, 2.8, 4.0, 1.3, 1], [4.4, 2.9, 1.4, 0.2, 0], [6.4, 3.2, 4.5, 1.5, 1], [6.3, 3.4, 5.6, 2.4, 2], [5.6, 2.8, 4.9, 2.0, 2], [6.5, 3.0, 5.5, 1.8, 2], [5.7, 2.9, 4.2, 1.3, 1], [4.9, 3.1, 1.5, 0.1, 0], [5.6, 2.9, 3.6, 1.3, 1], [6.0, 2.2, 4.0, 1.0, 1], [4.7, 3.2, 1.3, 0.2, 0], [6.8, 2.8, 4.8, 1.4, 1], [6.2, 3.4, 5.4, 2.3, 2], [5.1, 3.5, 1.4, 0.3, 0], [5.7, 2.8, 4.5, 1.3, 1], [4.7, 3.2, 1.6, 0.2, 0], [6.4, 3.1, 5.5, 1.8, 2], [5.9, 3.0, 4.2, 1.5, 1], [5.5, 3.5, 1.3, 0.2, 0], [7.1, 3.0, 5.9, 2.1, 2], [6.7, 3.3, 5.7, 2.1, 2], [5.6, 2.7, 4.2, 1.3, 1], [5.5, 2.5, 4.0, 1.3, 1], [5.7, 2.5, 5.0, 2.0, 2], [6.1, 2.9, 4.7, 1.4, 1], [6.6, 2.9, 4.6, 1.3, 1], [6.4, 2.8, 5.6, 2.1, 2], [5.0, 3.3, 1.4, 0.2, 0], [6.2, 2.8, 4.8, 1.8, 2], [4.3, 3.0, 1.1, 0.1, 0], [6.3, 3.3, 4.7, 1.6, 1], [5.8, 2.6, 4.0, 1.2, 1], [7.0, 3.2, 4.7, 1.4, 1], [6.0, 3.0, 4.8, 1.8, 2], [6.5, 3.0, 5.2, 2.0, 2], [6.1, 3.0, 4.6, 1.4, 1], [4.9, 3.1, 1.5, 0.1, 0], [6.1, 2.6, 5.6, 1.4, 2], [6.7, 3.1, 4.4, 1.4, 1], [6.8, 3.0, 5.5, 2.1, 2], [6.5, 3.0, 5.8, 2.2, 2], [6.7, 3.0, 5.0, 1.7, 1], [6.2, 2.2, 4.5, 1.5, 1], [5.6, 2.5, 3.9, 1.1, 1], [6.3, 3.3, 6.0, 2.5, 2], [6.7, 3.1, 5.6, 2.4, 2], [5.1, 3.8, 1.6, 0.2, 0], [4.6, 3.1, 1.5, 0.2, 0], [5.3, 3.7, 1.5, 0.2, 0], [6.9, 3.1, 5.4, 2.1, 2], [5.0, 3.5, 1.3, 0.3, 0], [5.1, 3.4, 1.5, 0.2, 0], [6.5, 3.2, 5.1, 2.0, 2], [6.3, 2.9, 5.6, 1.8, 2], [4.4, 3.2, 1.3, 0.2, 0], [5.8, 4.0, 1.2, 0.2, 0], [5.8, 2.7, 5.1, 1.9, 2], [5.2, 3.4, 1.4, 0.2, 0], [5.9, 3.2, 4.8, 1.8, 1], [5.0, 2.3, 3.3, 1.0, 1], [6.3, 2.5, 4.9, 1.5, 1], [6.0, 2.9, 4.5, 1.5, 1], [7.7, 2.6, 6.9, 2.3, 2], [5.2, 2.7, 3.9, 1.4, 1], [5.4, 3.7, 1.5, 0.2, 0], [4.6, 3.4, 1.4, 0.3, 0], [6.7, 3.0, 5.2, 2.3, 2], [6.7, 2.5, 5.8, 1.8, 2], [5.9, 3.0, 5.1, 1.8, 2], [6.7, 3.1, 4.7, 1.5, 1], [6.1, 3.0, 4.9, 1.8, 2], [7.2, 3.2, 6.0, 1.8, 2], [5.5, 2.6, 4.4, 1.2, 1], [5.0, 2.0, 3.5, 1.0, 1], [6.9, 3.1, 5.1, 2.3, 2], [5.4, 3.9, 1.7, 0.4, 0]]\n",
      "[[5.1, 2.5, 3.0, 1.1, 1], [6.4, 2.8, 5.6, 2.2, 2], [6.5, 2.8, 4.6, 1.5, 1], [5.0, 3.4, 1.6, 0.4, 0], [5.0, 3.2, 1.2, 0.2, 0], [5.2, 3.5, 1.5, 0.2, 0], [6.4, 2.7, 5.3, 1.9, 2], [5.8, 2.7, 4.1, 1.0, 1], [6.4, 2.9, 4.3, 1.3, 1], [5.8, 2.7, 3.9, 1.2, 1], [5.1, 3.3, 1.7, 0.5, 0], [5.7, 2.8, 4.1, 1.3, 1], [5.0, 3.4, 1.5, 0.2, 0], [5.6, 3.0, 4.1, 1.3, 1], [7.7, 2.8, 6.7, 2.0, 2], [5.5, 2.4, 3.7, 1.0, 1], [4.9, 3.1, 1.5, 0.1, 0], [6.2, 2.9, 4.3, 1.3, 1], [4.9, 2.4, 3.3, 1.0, 1], [4.8, 3.0, 1.4, 0.1, 0], [4.9, 3.0, 1.4, 0.2, 0], [4.8, 3.0, 1.4, 0.3, 0], [5.7, 4.4, 1.5, 0.4, 0], [6.6, 3.0, 4.4, 1.4, 1], [7.7, 3.8, 6.7, 2.2, 2], [6.3, 2.8, 5.1, 1.5, 2], [6.4, 3.2, 5.3, 2.3, 2], [7.2, 3.0, 5.8, 1.6, 2], [6.8, 3.2, 5.9, 2.3, 2]]\n",
      "[1, 2, 1, 0, 0, 0, 2, 1, 1, 1, 0, 1, 0, 1, 2, 1, 0, 1, 1, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2] ---------------\n",
      " [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[[5.1, 2.5, 3.0, 1.1, 1], [6.4, 2.8, 5.6, 2.2, 2], [6.5, 2.8, 4.6, 1.5, 1], [5.0, 3.4, 1.6, 0.4, 0], [5.0, 3.2, 1.2, 0.2, 0], [5.2, 3.5, 1.5, 0.2, 0], [6.4, 2.7, 5.3, 1.9, 2], [5.8, 2.7, 4.1, 1.0, 1], [6.4, 2.9, 4.3, 1.3, 1], [5.8, 2.7, 3.9, 1.2, 1], [5.1, 3.3, 1.7, 0.5, 0], [5.7, 2.8, 4.1, 1.3, 1], [5.0, 3.4, 1.5, 0.2, 0], [5.6, 3.0, 4.1, 1.3, 1], [7.7, 2.8, 6.7, 2.0, 2], [5.5, 2.4, 3.7, 1.0, 1], [4.9, 3.1, 1.5, 0.1, 0], [6.2, 2.9, 4.3, 1.3, 1], [4.9, 2.4, 3.3, 1.0, 1], [4.8, 3.0, 1.4, 0.1, 0], [4.9, 3.0, 1.4, 0.2, 0], [4.8, 3.0, 1.4, 0.3, 0], [5.7, 4.4, 1.5, 0.4, 0], [6.6, 3.0, 4.4, 1.4, 1], [7.7, 3.8, 6.7, 2.2, 2], [6.3, 2.8, 5.1, 1.5, 2], [6.4, 3.2, 5.3, 2.3, 2], [7.2, 3.0, 5.8, 1.6, 2], [6.8, 3.2, 5.9, 2.3, 2], [6.0, 2.2, 5.0, 1.5, 2], [5.4, 3.4, 1.7, 0.2, 0], [7.4, 2.8, 6.1, 1.9, 2], [6.3, 2.3, 4.4, 1.3, 1], [4.5, 2.3, 1.3, 0.3, 0], [5.0, 3.6, 1.4, 0.2, 0], [5.5, 4.2, 1.4, 0.2, 0], [5.7, 3.8, 1.7, 0.3, 0], [6.3, 2.7, 4.9, 1.8, 2], [5.6, 3.0, 4.5, 1.5, 1], [7.7, 3.0, 6.1, 2.3, 2], [6.1, 2.8, 4.0, 1.3, 1], [4.4, 2.9, 1.4, 0.2, 0], [6.4, 3.2, 4.5, 1.5, 1], [6.3, 3.4, 5.6, 2.4, 2], [5.6, 2.8, 4.9, 2.0, 2], [6.5, 3.0, 5.5, 1.8, 2], [5.7, 2.9, 4.2, 1.3, 1], [4.9, 3.1, 1.5, 0.1, 0], [5.6, 2.9, 3.6, 1.3, 1], [6.0, 2.2, 4.0, 1.0, 1], [4.7, 3.2, 1.3, 0.2, 0], [6.8, 2.8, 4.8, 1.4, 1], [6.2, 3.4, 5.4, 2.3, 2], [5.1, 3.5, 1.4, 0.3, 0], [5.7, 2.8, 4.5, 1.3, 1], [4.7, 3.2, 1.6, 0.2, 0], [6.4, 3.1, 5.5, 1.8, 2], [5.9, 3.0, 4.2, 1.5, 1], [5.5, 3.5, 1.3, 0.2, 0], [7.1, 3.0, 5.9, 2.1, 2], [6.7, 3.3, 5.7, 2.1, 2], [5.6, 2.7, 4.2, 1.3, 1], [5.5, 2.5, 4.0, 1.3, 1], [5.7, 2.5, 5.0, 2.0, 2], [6.1, 2.9, 4.7, 1.4, 1], [6.6, 2.9, 4.6, 1.3, 1], [6.4, 2.8, 5.6, 2.1, 2], [5.0, 3.3, 1.4, 0.2, 0], [6.2, 2.8, 4.8, 1.8, 2], [4.3, 3.0, 1.1, 0.1, 0], [6.3, 3.3, 4.7, 1.6, 1], [5.8, 2.6, 4.0, 1.2, 1], [7.0, 3.2, 4.7, 1.4, 1], [6.0, 3.0, 4.8, 1.8, 2], [6.5, 3.0, 5.2, 2.0, 2], [6.1, 3.0, 4.6, 1.4, 1], [4.9, 3.1, 1.5, 0.1, 0], [6.1, 2.6, 5.6, 1.4, 2], [6.7, 3.1, 4.4, 1.4, 1], [6.8, 3.0, 5.5, 2.1, 2], [6.5, 3.0, 5.8, 2.2, 2], [6.7, 3.0, 5.0, 1.7, 1], [6.2, 2.2, 4.5, 1.5, 1], [5.6, 2.5, 3.9, 1.1, 1], [6.3, 3.3, 6.0, 2.5, 2], [6.7, 3.1, 5.6, 2.4, 2], [5.1, 3.8, 1.6, 0.2, 0], [4.6, 3.1, 1.5, 0.2, 0], [5.3, 3.7, 1.5, 0.2, 0], [6.9, 3.1, 5.4, 2.1, 2], [5.0, 3.5, 1.3, 0.3, 0], [5.1, 3.4, 1.5, 0.2, 0], [6.5, 3.2, 5.1, 2.0, 2], [6.3, 2.9, 5.6, 1.8, 2], [4.4, 3.2, 1.3, 0.2, 0], [5.8, 4.0, 1.2, 0.2, 0], [5.8, 2.7, 5.1, 1.9, 2], [5.2, 3.4, 1.4, 0.2, 0], [5.9, 3.2, 4.8, 1.8, 1], [5.0, 2.3, 3.3, 1.0, 1], [6.3, 2.5, 4.9, 1.5, 1], [6.0, 2.9, 4.5, 1.5, 1], [7.7, 2.6, 6.9, 2.3, 2], [5.2, 2.7, 3.9, 1.4, 1], [5.4, 3.7, 1.5, 0.2, 0], [4.6, 3.4, 1.4, 0.3, 0], [6.7, 3.0, 5.2, 2.3, 2], [6.7, 2.5, 5.8, 1.8, 2], [5.9, 3.0, 5.1, 1.8, 2], [6.7, 3.1, 4.7, 1.5, 1], [6.1, 3.0, 4.9, 1.8, 2], [7.2, 3.2, 6.0, 1.8, 2], [5.5, 2.6, 4.4, 1.2, 1], [5.0, 2.0, 3.5, 1.0, 1], [6.9, 3.1, 5.1, 2.3, 2], [5.4, 3.9, 1.7, 0.4, 0]]\n",
      "[[5.4, 3.9, 1.3, 0.4, 0], [5.4, 3.0, 4.5, 1.5, 1], [6.1, 2.8, 4.7, 1.2, 1], [5.1, 3.7, 1.5, 0.4, 0], [5.0, 3.5, 1.6, 0.6, 0], [5.8, 2.8, 5.1, 2.4, 2], [5.7, 3.0, 4.2, 1.2, 1], [6.9, 3.1, 4.9, 1.5, 1], [4.6, 3.2, 1.4, 0.2, 0], [7.9, 3.8, 6.4, 2.0, 2], [7.6, 3.0, 6.6, 2.1, 2], [5.1, 3.8, 1.9, 0.4, 0], [5.2, 4.1, 1.5, 0.1, 0], [6.9, 3.2, 5.7, 2.3, 2], [5.1, 3.8, 1.5, 0.3, 0], [6.3, 2.5, 5.0, 1.9, 2], [6.0, 3.4, 4.5, 1.6, 1], [5.8, 2.7, 5.1, 1.9, 2], [5.7, 2.6, 3.5, 1.0, 1], [5.5, 2.3, 4.0, 1.3, 1], [4.8, 3.4, 1.9, 0.2, 0], [7.3, 2.9, 6.3, 1.8, 2], [4.8, 3.4, 1.6, 0.2, 0], [5.5, 2.4, 3.8, 1.1, 1], [4.6, 3.6, 1.0, 0.2, 0], [6.7, 3.3, 5.7, 2.5, 2], [5.0, 3.0, 1.6, 0.2, 0], [4.9, 2.5, 4.5, 1.7, 2], [6.0, 2.7, 5.1, 1.6, 1]]\n",
      "[0, 1, 1, 0, 0, 2, 1, 1, 0, 2, 2, 0, 0, 2, 0, 2, 1, 2, 1, 1, 0, 2, 0, 1, 0, 2, 0, 2, 1] ---------------\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[5.1, 2.5, 3.0, 1.1, 1], [6.4, 2.8, 5.6, 2.2, 2], [6.5, 2.8, 4.6, 1.5, 1], [5.0, 3.4, 1.6, 0.4, 0], [5.0, 3.2, 1.2, 0.2, 0], [5.2, 3.5, 1.5, 0.2, 0], [6.4, 2.7, 5.3, 1.9, 2], [5.8, 2.7, 4.1, 1.0, 1], [6.4, 2.9, 4.3, 1.3, 1], [5.8, 2.7, 3.9, 1.2, 1], [5.1, 3.3, 1.7, 0.5, 0], [5.7, 2.8, 4.1, 1.3, 1], [5.0, 3.4, 1.5, 0.2, 0], [5.6, 3.0, 4.1, 1.3, 1], [7.7, 2.8, 6.7, 2.0, 2], [5.5, 2.4, 3.7, 1.0, 1], [4.9, 3.1, 1.5, 0.1, 0], [6.2, 2.9, 4.3, 1.3, 1], [4.9, 2.4, 3.3, 1.0, 1], [4.8, 3.0, 1.4, 0.1, 0], [4.9, 3.0, 1.4, 0.2, 0], [4.8, 3.0, 1.4, 0.3, 0], [5.7, 4.4, 1.5, 0.4, 0], [6.6, 3.0, 4.4, 1.4, 1], [7.7, 3.8, 6.7, 2.2, 2], [6.3, 2.8, 5.1, 1.5, 2], [6.4, 3.2, 5.3, 2.3, 2], [7.2, 3.0, 5.8, 1.6, 2], [6.8, 3.2, 5.9, 2.3, 2], [5.4, 3.9, 1.3, 0.4, 0], [5.4, 3.0, 4.5, 1.5, 1], [6.1, 2.8, 4.7, 1.2, 1], [5.1, 3.7, 1.5, 0.4, 0], [5.0, 3.5, 1.6, 0.6, 0], [5.8, 2.8, 5.1, 2.4, 2], [5.7, 3.0, 4.2, 1.2, 1], [6.9, 3.1, 4.9, 1.5, 1], [4.6, 3.2, 1.4, 0.2, 0], [7.9, 3.8, 6.4, 2.0, 2], [7.6, 3.0, 6.6, 2.1, 2], [5.1, 3.8, 1.9, 0.4, 0], [5.2, 4.1, 1.5, 0.1, 0], [6.9, 3.2, 5.7, 2.3, 2], [5.1, 3.8, 1.5, 0.3, 0], [6.3, 2.5, 5.0, 1.9, 2], [6.0, 3.4, 4.5, 1.6, 1], [5.8, 2.7, 5.1, 1.9, 2], [5.7, 2.6, 3.5, 1.0, 1], [5.5, 2.3, 4.0, 1.3, 1], [4.8, 3.4, 1.9, 0.2, 0], [7.3, 2.9, 6.3, 1.8, 2], [4.8, 3.4, 1.6, 0.2, 0], [5.5, 2.4, 3.8, 1.1, 1], [4.6, 3.6, 1.0, 0.2, 0], [6.7, 3.3, 5.7, 2.5, 2], [5.0, 3.0, 1.6, 0.2, 0], [4.9, 2.5, 4.5, 1.7, 2], [6.0, 2.7, 5.1, 1.6, 1], [5.5, 3.5, 1.3, 0.2, 0], [7.1, 3.0, 5.9, 2.1, 2], [6.7, 3.3, 5.7, 2.1, 2], [5.6, 2.7, 4.2, 1.3, 1], [5.5, 2.5, 4.0, 1.3, 1], [5.7, 2.5, 5.0, 2.0, 2], [6.1, 2.9, 4.7, 1.4, 1], [6.6, 2.9, 4.6, 1.3, 1], [6.4, 2.8, 5.6, 2.1, 2], [5.0, 3.3, 1.4, 0.2, 0], [6.2, 2.8, 4.8, 1.8, 2], [4.3, 3.0, 1.1, 0.1, 0], [6.3, 3.3, 4.7, 1.6, 1], [5.8, 2.6, 4.0, 1.2, 1], [7.0, 3.2, 4.7, 1.4, 1], [6.0, 3.0, 4.8, 1.8, 2], [6.5, 3.0, 5.2, 2.0, 2], [6.1, 3.0, 4.6, 1.4, 1], [4.9, 3.1, 1.5, 0.1, 0], [6.1, 2.6, 5.6, 1.4, 2], [6.7, 3.1, 4.4, 1.4, 1], [6.8, 3.0, 5.5, 2.1, 2], [6.5, 3.0, 5.8, 2.2, 2], [6.7, 3.0, 5.0, 1.7, 1], [6.2, 2.2, 4.5, 1.5, 1], [5.6, 2.5, 3.9, 1.1, 1], [6.3, 3.3, 6.0, 2.5, 2], [6.7, 3.1, 5.6, 2.4, 2], [5.1, 3.8, 1.6, 0.2, 0], [4.6, 3.1, 1.5, 0.2, 0], [5.3, 3.7, 1.5, 0.2, 0], [6.9, 3.1, 5.4, 2.1, 2], [5.0, 3.5, 1.3, 0.3, 0], [5.1, 3.4, 1.5, 0.2, 0], [6.5, 3.2, 5.1, 2.0, 2], [6.3, 2.9, 5.6, 1.8, 2], [4.4, 3.2, 1.3, 0.2, 0], [5.8, 4.0, 1.2, 0.2, 0], [5.8, 2.7, 5.1, 1.9, 2], [5.2, 3.4, 1.4, 0.2, 0], [5.9, 3.2, 4.8, 1.8, 1], [5.0, 2.3, 3.3, 1.0, 1], [6.3, 2.5, 4.9, 1.5, 1], [6.0, 2.9, 4.5, 1.5, 1], [7.7, 2.6, 6.9, 2.3, 2], [5.2, 2.7, 3.9, 1.4, 1], [5.4, 3.7, 1.5, 0.2, 0], [4.6, 3.4, 1.4, 0.3, 0], [6.7, 3.0, 5.2, 2.3, 2], [6.7, 2.5, 5.8, 1.8, 2], [5.9, 3.0, 5.1, 1.8, 2], [6.7, 3.1, 4.7, 1.5, 1], [6.1, 3.0, 4.9, 1.8, 2], [7.2, 3.2, 6.0, 1.8, 2], [5.5, 2.6, 4.4, 1.2, 1], [5.0, 2.0, 3.5, 1.0, 1], [6.9, 3.1, 5.1, 2.3, 2], [5.4, 3.9, 1.7, 0.4, 0]]\n",
      "[[6.0, 2.2, 5.0, 1.5, 2], [5.4, 3.4, 1.7, 0.2, 0], [7.4, 2.8, 6.1, 1.9, 2], [6.3, 2.3, 4.4, 1.3, 1], [4.5, 2.3, 1.3, 0.3, 0], [5.0, 3.6, 1.4, 0.2, 0], [5.5, 4.2, 1.4, 0.2, 0], [5.7, 3.8, 1.7, 0.3, 0], [6.3, 2.7, 4.9, 1.8, 2], [5.6, 3.0, 4.5, 1.5, 1], [7.7, 3.0, 6.1, 2.3, 2], [6.1, 2.8, 4.0, 1.3, 1], [4.4, 2.9, 1.4, 0.2, 0], [6.4, 3.2, 4.5, 1.5, 1], [6.3, 3.4, 5.6, 2.4, 2], [5.6, 2.8, 4.9, 2.0, 2], [6.5, 3.0, 5.5, 1.8, 2], [5.7, 2.9, 4.2, 1.3, 1], [4.9, 3.1, 1.5, 0.1, 0], [5.6, 2.9, 3.6, 1.3, 1], [6.0, 2.2, 4.0, 1.0, 1], [4.7, 3.2, 1.3, 0.2, 0], [6.8, 2.8, 4.8, 1.4, 1], [6.2, 3.4, 5.4, 2.3, 2], [5.1, 3.5, 1.4, 0.3, 0], [5.7, 2.8, 4.5, 1.3, 1], [4.7, 3.2, 1.6, 0.2, 0], [6.4, 3.1, 5.5, 1.8, 2], [5.9, 3.0, 4.2, 1.5, 1]]\n",
      "[2, 0, 2, 1, 0, 0, 0, 0, 2, 1, 2, 1, 0, 1, 2, 2, 2, 1, 0, 1, 1, 0, 1, 2, 0, 1, 0, 2, 1] ---------------\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[5.1, 2.5, 3.0, 1.1, 1], [6.4, 2.8, 5.6, 2.2, 2], [6.5, 2.8, 4.6, 1.5, 1], [5.0, 3.4, 1.6, 0.4, 0], [5.0, 3.2, 1.2, 0.2, 0], [5.2, 3.5, 1.5, 0.2, 0], [6.4, 2.7, 5.3, 1.9, 2], [5.8, 2.7, 4.1, 1.0, 1], [6.4, 2.9, 4.3, 1.3, 1], [5.8, 2.7, 3.9, 1.2, 1], [5.1, 3.3, 1.7, 0.5, 0], [5.7, 2.8, 4.1, 1.3, 1], [5.0, 3.4, 1.5, 0.2, 0], [5.6, 3.0, 4.1, 1.3, 1], [7.7, 2.8, 6.7, 2.0, 2], [5.5, 2.4, 3.7, 1.0, 1], [4.9, 3.1, 1.5, 0.1, 0], [6.2, 2.9, 4.3, 1.3, 1], [4.9, 2.4, 3.3, 1.0, 1], [4.8, 3.0, 1.4, 0.1, 0], [4.9, 3.0, 1.4, 0.2, 0], [4.8, 3.0, 1.4, 0.3, 0], [5.7, 4.4, 1.5, 0.4, 0], [6.6, 3.0, 4.4, 1.4, 1], [7.7, 3.8, 6.7, 2.2, 2], [6.3, 2.8, 5.1, 1.5, 2], [6.4, 3.2, 5.3, 2.3, 2], [7.2, 3.0, 5.8, 1.6, 2], [6.8, 3.2, 5.9, 2.3, 2], [5.4, 3.9, 1.3, 0.4, 0], [5.4, 3.0, 4.5, 1.5, 1], [6.1, 2.8, 4.7, 1.2, 1], [5.1, 3.7, 1.5, 0.4, 0], [5.0, 3.5, 1.6, 0.6, 0], [5.8, 2.8, 5.1, 2.4, 2], [5.7, 3.0, 4.2, 1.2, 1], [6.9, 3.1, 4.9, 1.5, 1], [4.6, 3.2, 1.4, 0.2, 0], [7.9, 3.8, 6.4, 2.0, 2], [7.6, 3.0, 6.6, 2.1, 2], [5.1, 3.8, 1.9, 0.4, 0], [5.2, 4.1, 1.5, 0.1, 0], [6.9, 3.2, 5.7, 2.3, 2], [5.1, 3.8, 1.5, 0.3, 0], [6.3, 2.5, 5.0, 1.9, 2], [6.0, 3.4, 4.5, 1.6, 1], [5.8, 2.7, 5.1, 1.9, 2], [5.7, 2.6, 3.5, 1.0, 1], [5.5, 2.3, 4.0, 1.3, 1], [4.8, 3.4, 1.9, 0.2, 0], [7.3, 2.9, 6.3, 1.8, 2], [4.8, 3.4, 1.6, 0.2, 0], [5.5, 2.4, 3.8, 1.1, 1], [4.6, 3.6, 1.0, 0.2, 0], [6.7, 3.3, 5.7, 2.5, 2], [5.0, 3.0, 1.6, 0.2, 0], [4.9, 2.5, 4.5, 1.7, 2], [6.0, 2.7, 5.1, 1.6, 1], [6.0, 2.2, 5.0, 1.5, 2], [5.4, 3.4, 1.7, 0.2, 0], [7.4, 2.8, 6.1, 1.9, 2], [6.3, 2.3, 4.4, 1.3, 1], [4.5, 2.3, 1.3, 0.3, 0], [5.0, 3.6, 1.4, 0.2, 0], [5.5, 4.2, 1.4, 0.2, 0], [5.7, 3.8, 1.7, 0.3, 0], [6.3, 2.7, 4.9, 1.8, 2], [5.6, 3.0, 4.5, 1.5, 1], [7.7, 3.0, 6.1, 2.3, 2], [6.1, 2.8, 4.0, 1.3, 1], [4.4, 2.9, 1.4, 0.2, 0], [6.4, 3.2, 4.5, 1.5, 1], [6.3, 3.4, 5.6, 2.4, 2], [5.6, 2.8, 4.9, 2.0, 2], [6.5, 3.0, 5.5, 1.8, 2], [5.7, 2.9, 4.2, 1.3, 1], [4.9, 3.1, 1.5, 0.1, 0], [5.6, 2.9, 3.6, 1.3, 1], [6.0, 2.2, 4.0, 1.0, 1], [4.7, 3.2, 1.3, 0.2, 0], [6.8, 2.8, 4.8, 1.4, 1], [6.2, 3.4, 5.4, 2.3, 2], [5.1, 3.5, 1.4, 0.3, 0], [5.7, 2.8, 4.5, 1.3, 1], [4.7, 3.2, 1.6, 0.2, 0], [6.4, 3.1, 5.5, 1.8, 2], [5.9, 3.0, 4.2, 1.5, 1], [4.6, 3.1, 1.5, 0.2, 0], [5.3, 3.7, 1.5, 0.2, 0], [6.9, 3.1, 5.4, 2.1, 2], [5.0, 3.5, 1.3, 0.3, 0], [5.1, 3.4, 1.5, 0.2, 0], [6.5, 3.2, 5.1, 2.0, 2], [6.3, 2.9, 5.6, 1.8, 2], [4.4, 3.2, 1.3, 0.2, 0], [5.8, 4.0, 1.2, 0.2, 0], [5.8, 2.7, 5.1, 1.9, 2], [5.2, 3.4, 1.4, 0.2, 0], [5.9, 3.2, 4.8, 1.8, 1], [5.0, 2.3, 3.3, 1.0, 1], [6.3, 2.5, 4.9, 1.5, 1], [6.0, 2.9, 4.5, 1.5, 1], [7.7, 2.6, 6.9, 2.3, 2], [5.2, 2.7, 3.9, 1.4, 1], [5.4, 3.7, 1.5, 0.2, 0], [4.6, 3.4, 1.4, 0.3, 0], [6.7, 3.0, 5.2, 2.3, 2], [6.7, 2.5, 5.8, 1.8, 2], [5.9, 3.0, 5.1, 1.8, 2], [6.7, 3.1, 4.7, 1.5, 1], [6.1, 3.0, 4.9, 1.8, 2], [7.2, 3.2, 6.0, 1.8, 2], [5.5, 2.6, 4.4, 1.2, 1], [5.0, 2.0, 3.5, 1.0, 1], [6.9, 3.1, 5.1, 2.3, 2], [5.4, 3.9, 1.7, 0.4, 0]]\n",
      "[[5.5, 3.5, 1.3, 0.2, 0], [7.1, 3.0, 5.9, 2.1, 2], [6.7, 3.3, 5.7, 2.1, 2], [5.6, 2.7, 4.2, 1.3, 1], [5.5, 2.5, 4.0, 1.3, 1], [5.7, 2.5, 5.0, 2.0, 2], [6.1, 2.9, 4.7, 1.4, 1], [6.6, 2.9, 4.6, 1.3, 1], [6.4, 2.8, 5.6, 2.1, 2], [5.0, 3.3, 1.4, 0.2, 0], [6.2, 2.8, 4.8, 1.8, 2], [4.3, 3.0, 1.1, 0.1, 0], [6.3, 3.3, 4.7, 1.6, 1], [5.8, 2.6, 4.0, 1.2, 1], [7.0, 3.2, 4.7, 1.4, 1], [6.0, 3.0, 4.8, 1.8, 2], [6.5, 3.0, 5.2, 2.0, 2], [6.1, 3.0, 4.6, 1.4, 1], [4.9, 3.1, 1.5, 0.1, 0], [6.1, 2.6, 5.6, 1.4, 2], [6.7, 3.1, 4.4, 1.4, 1], [6.8, 3.0, 5.5, 2.1, 2], [6.5, 3.0, 5.8, 2.2, 2], [6.7, 3.0, 5.0, 1.7, 1], [6.2, 2.2, 4.5, 1.5, 1], [5.6, 2.5, 3.9, 1.1, 1], [6.3, 3.3, 6.0, 2.5, 2], [6.7, 3.1, 5.6, 2.4, 2], [5.1, 3.8, 1.6, 0.2, 0]]\n",
      "[0, 2, 2, 1, 1, 2, 1, 1, 2, 0, 2, 0, 1, 1, 1, 2, 2, 1, 0, 2, 1, 2, 2, 1, 1, 1, 2, 2, 0] ---------------\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[5.1, 2.5, 3.0, 1.1, 1], [6.4, 2.8, 5.6, 2.2, 2], [6.5, 2.8, 4.6, 1.5, 1], [5.0, 3.4, 1.6, 0.4, 0], [5.0, 3.2, 1.2, 0.2, 0], [5.2, 3.5, 1.5, 0.2, 0], [6.4, 2.7, 5.3, 1.9, 2], [5.8, 2.7, 4.1, 1.0, 1], [6.4, 2.9, 4.3, 1.3, 1], [5.8, 2.7, 3.9, 1.2, 1], [5.1, 3.3, 1.7, 0.5, 0], [5.7, 2.8, 4.1, 1.3, 1], [5.0, 3.4, 1.5, 0.2, 0], [5.6, 3.0, 4.1, 1.3, 1], [7.7, 2.8, 6.7, 2.0, 2], [5.5, 2.4, 3.7, 1.0, 1], [4.9, 3.1, 1.5, 0.1, 0], [6.2, 2.9, 4.3, 1.3, 1], [4.9, 2.4, 3.3, 1.0, 1], [4.8, 3.0, 1.4, 0.1, 0], [4.9, 3.0, 1.4, 0.2, 0], [4.8, 3.0, 1.4, 0.3, 0], [5.7, 4.4, 1.5, 0.4, 0], [6.6, 3.0, 4.4, 1.4, 1], [7.7, 3.8, 6.7, 2.2, 2], [6.3, 2.8, 5.1, 1.5, 2], [6.4, 3.2, 5.3, 2.3, 2], [7.2, 3.0, 5.8, 1.6, 2], [6.8, 3.2, 5.9, 2.3, 2], [5.4, 3.9, 1.3, 0.4, 0], [5.4, 3.0, 4.5, 1.5, 1], [6.1, 2.8, 4.7, 1.2, 1], [5.1, 3.7, 1.5, 0.4, 0], [5.0, 3.5, 1.6, 0.6, 0], [5.8, 2.8, 5.1, 2.4, 2], [5.7, 3.0, 4.2, 1.2, 1], [6.9, 3.1, 4.9, 1.5, 1], [4.6, 3.2, 1.4, 0.2, 0], [7.9, 3.8, 6.4, 2.0, 2], [7.6, 3.0, 6.6, 2.1, 2], [5.1, 3.8, 1.9, 0.4, 0], [5.2, 4.1, 1.5, 0.1, 0], [6.9, 3.2, 5.7, 2.3, 2], [5.1, 3.8, 1.5, 0.3, 0], [6.3, 2.5, 5.0, 1.9, 2], [6.0, 3.4, 4.5, 1.6, 1], [5.8, 2.7, 5.1, 1.9, 2], [5.7, 2.6, 3.5, 1.0, 1], [5.5, 2.3, 4.0, 1.3, 1], [4.8, 3.4, 1.9, 0.2, 0], [7.3, 2.9, 6.3, 1.8, 2], [4.8, 3.4, 1.6, 0.2, 0], [5.5, 2.4, 3.8, 1.1, 1], [4.6, 3.6, 1.0, 0.2, 0], [6.7, 3.3, 5.7, 2.5, 2], [5.0, 3.0, 1.6, 0.2, 0], [4.9, 2.5, 4.5, 1.7, 2], [6.0, 2.7, 5.1, 1.6, 1], [6.0, 2.2, 5.0, 1.5, 2], [5.4, 3.4, 1.7, 0.2, 0], [7.4, 2.8, 6.1, 1.9, 2], [6.3, 2.3, 4.4, 1.3, 1], [4.5, 2.3, 1.3, 0.3, 0], [5.0, 3.6, 1.4, 0.2, 0], [5.5, 4.2, 1.4, 0.2, 0], [5.7, 3.8, 1.7, 0.3, 0], [6.3, 2.7, 4.9, 1.8, 2], [5.6, 3.0, 4.5, 1.5, 1], [7.7, 3.0, 6.1, 2.3, 2], [6.1, 2.8, 4.0, 1.3, 1], [4.4, 2.9, 1.4, 0.2, 0], [6.4, 3.2, 4.5, 1.5, 1], [6.3, 3.4, 5.6, 2.4, 2], [5.6, 2.8, 4.9, 2.0, 2], [6.5, 3.0, 5.5, 1.8, 2], [5.7, 2.9, 4.2, 1.3, 1], [4.9, 3.1, 1.5, 0.1, 0], [5.6, 2.9, 3.6, 1.3, 1], [6.0, 2.2, 4.0, 1.0, 1], [4.7, 3.2, 1.3, 0.2, 0], [6.8, 2.8, 4.8, 1.4, 1], [6.2, 3.4, 5.4, 2.3, 2], [5.1, 3.5, 1.4, 0.3, 0], [5.7, 2.8, 4.5, 1.3, 1], [4.7, 3.2, 1.6, 0.2, 0], [6.4, 3.1, 5.5, 1.8, 2], [5.9, 3.0, 4.2, 1.5, 1], [5.5, 3.5, 1.3, 0.2, 0], [7.1, 3.0, 5.9, 2.1, 2], [6.7, 3.3, 5.7, 2.1, 2], [5.6, 2.7, 4.2, 1.3, 1], [5.5, 2.5, 4.0, 1.3, 1], [5.7, 2.5, 5.0, 2.0, 2], [6.1, 2.9, 4.7, 1.4, 1], [6.6, 2.9, 4.6, 1.3, 1], [6.4, 2.8, 5.6, 2.1, 2], [5.0, 3.3, 1.4, 0.2, 0], [6.2, 2.8, 4.8, 1.8, 2], [4.3, 3.0, 1.1, 0.1, 0], [6.3, 3.3, 4.7, 1.6, 1], [5.8, 2.6, 4.0, 1.2, 1], [7.0, 3.2, 4.7, 1.4, 1], [6.0, 3.0, 4.8, 1.8, 2], [6.5, 3.0, 5.2, 2.0, 2], [6.1, 3.0, 4.6, 1.4, 1], [4.9, 3.1, 1.5, 0.1, 0], [6.1, 2.6, 5.6, 1.4, 2], [6.7, 3.1, 4.4, 1.4, 1], [6.8, 3.0, 5.5, 2.1, 2], [6.5, 3.0, 5.8, 2.2, 2], [6.7, 3.0, 5.0, 1.7, 1], [6.2, 2.2, 4.5, 1.5, 1], [5.6, 2.5, 3.9, 1.1, 1], [6.3, 3.3, 6.0, 2.5, 2], [6.7, 3.1, 5.6, 2.4, 2], [5.1, 3.8, 1.6, 0.2, 0]]\n",
      "[[4.6, 3.1, 1.5, 0.2, 0], [5.3, 3.7, 1.5, 0.2, 0], [6.9, 3.1, 5.4, 2.1, 2], [5.0, 3.5, 1.3, 0.3, 0], [5.1, 3.4, 1.5, 0.2, 0], [6.5, 3.2, 5.1, 2.0, 2], [6.3, 2.9, 5.6, 1.8, 2], [4.4, 3.2, 1.3, 0.2, 0], [5.8, 4.0, 1.2, 0.2, 0], [5.8, 2.7, 5.1, 1.9, 2], [5.2, 3.4, 1.4, 0.2, 0], [5.9, 3.2, 4.8, 1.8, 1], [5.0, 2.3, 3.3, 1.0, 1], [6.3, 2.5, 4.9, 1.5, 1], [6.0, 2.9, 4.5, 1.5, 1], [7.7, 2.6, 6.9, 2.3, 2], [5.2, 2.7, 3.9, 1.4, 1], [5.4, 3.7, 1.5, 0.2, 0], [4.6, 3.4, 1.4, 0.3, 0], [6.7, 3.0, 5.2, 2.3, 2], [6.7, 2.5, 5.8, 1.8, 2], [5.9, 3.0, 5.1, 1.8, 2], [6.7, 3.1, 4.7, 1.5, 1], [6.1, 3.0, 4.9, 1.8, 2], [7.2, 3.2, 6.0, 1.8, 2], [5.5, 2.6, 4.4, 1.2, 1], [5.0, 2.0, 3.5, 1.0, 1], [6.9, 3.1, 5.1, 2.3, 2], [5.4, 3.9, 1.7, 0.4, 0]]\n",
      "[0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 1, 1, 1, 1, 2, 1, 0, 0, 2, 2, 2, 1, 2, 2, 1, 1, 2, 0] ---------------\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Scores: [27.586206896551722, 37.93103448275862, 34.48275862068966, 17.24137931034483, 34.48275862068966]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('iris.csv')\n",
    "data=data.values.tolist()\n",
    "for i in range(len(data[0])-1):\n",
    "\tstr_column_to_float(data, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(data, len(data[0])-1)\n",
    "\n",
    "dataset=data\n",
    "\n",
    "n_folds = 5\n",
    "scores = evaluate_algorithm(data,naive_bayes, n_folds)\n",
    "print('Scores: %s' % scores)\n",
    "# print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "CtU7I3EiZRQ5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "G8crlcsZKXxn"
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import random\n",
    "# import math\n",
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "# def loadcsv(dataset):\n",
    "# \t# lines = csv.reader(open(filename, \"r\"));\n",
    "# \t# dataset = list(data)\n",
    "# \tfor i in range(len(dataset)):\n",
    "#        #converting strings into numbers for processing\n",
    "# \t\tdataset[i] = [float(x) for x in dataset[i]]\n",
    "        \n",
    "# \treturn dataset\n",
    " \n",
    "# def splitdataset(dataset, splitratio):\n",
    "#     #67% training size\n",
    "# \ttrainsize = int(len(dataset) * splitratio);\n",
    "# \ttrainset = []\n",
    "# \tcopy = list(dataset);    \n",
    "# \twhile len(trainset) < trainsize:\n",
    "# #generate indices for the dataset list randomly to pick ele for training data\n",
    "# \t\tindex = random.randrange(len(copy));       \n",
    "# \t\ttrainset.append(copy.pop(index))    \n",
    "# \treturn [trainset, copy]\n",
    " \n",
    "# def separatebyclass(dataset):\n",
    "# \tseparated = {} #dictionary of classes 1 and 0 \n",
    "# #creates a dictionary of classes 1 and 0 where the values are \n",
    "# #the instances belonging to each class\n",
    "# \tfor i in range(len(dataset)):\n",
    "# \t\tvector = dataset[i]\n",
    "# \t\tif (vector[-1] not in separated):\n",
    "# \t\t\tseparated[vector[-1]] = []\n",
    "# \t\tseparated[vector[-1]].append(vector)\n",
    "# \treturn separated\n",
    " \n",
    "# def mean(numbers):\n",
    "# \treturn sum(numbers)/float(len(numbers))\n",
    " \n",
    "# def stdev(numbers):\n",
    "# \tavg = mean(numbers)\n",
    "# \tvariance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "# \treturn math.sqrt(variance)\n",
    " \n",
    "# def summarize(dataset): #creates a dictionary of classes\n",
    "# \tsummaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)];\n",
    "# \tdel summaries[-1] #excluding labels +ve or -ve\n",
    "# \treturn summaries\n",
    " \n",
    "# def summarizebyclass(dataset):\n",
    "# \tseparated = separatebyclass(dataset); \n",
    "#     #print(separated)\n",
    "# \tsummaries = {}\n",
    "# \tfor classvalue, instances in separated.items(): \n",
    "# #for key,value in dic.items()\n",
    "# #summaries is a dic of tuples(mean,std) for each class value        \n",
    "# \t\tsummaries[classvalue] = summarize(instances) #summarize is used to cal to mean and std\n",
    "# \treturn summaries\n",
    " \n",
    "# def calculateprobability(x, mean, stdev):\n",
    "# \texponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "# \treturn (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    " \n",
    "# def calculateclassprobabilities(summaries, inputvector):\n",
    "# \tprobabilities = {} # probabilities contains the all prob of all class of test data\n",
    "# \tfor classvalue, classsummaries in summaries.items():#class and attribute information as mean and sd\n",
    "# \t\tprobabilities[classvalue] = 1\n",
    "# \t\tfor i in range(len(classsummaries)):\n",
    "# \t\t\tmean, stdev = classsummaries[i] #take mean and sd of every attribute for class 0 and 1 seperaely\n",
    "# \t\t\tx = inputvector[i] #testvector's first attribute\n",
    "# \t\t\tprobabilities[classvalue] *= calculateprobability(x, mean, stdev);#use normal dist\n",
    "# \treturn probabilities\n",
    "\t\t\t\n",
    "# def predict(summaries, inputvector): #training and test data is passed\n",
    "# \tprobabilities = calculateclassprobabilities(summaries, inputvector)\n",
    "# \tbestLabel, bestProb = None, -1\n",
    "# \tfor classvalue, probability in probabilities.items():#assigns that class which has he highest prob\n",
    "# \t\tif bestLabel is None or probability > bestProb:\n",
    "# \t\t\tbestProb = probability\n",
    "# \t\t\tbestLabel = classvalue\n",
    "# \treturn bestLabel\n",
    " \n",
    "# def getpredictions(summaries, testset):\n",
    "# \tpredictions = []\n",
    "# \tfor i in range(len(testset)):\n",
    "# \t\tresult = predict(summaries, testset[i])\n",
    "# \t\tpredictions.append(result)\n",
    "# \treturn predictions\n",
    " \n",
    "# def getaccuracy(testset, predictions):\n",
    "# \tcorrect = 0\n",
    "# \tfor i in range(len(testset)):\n",
    "# \t\tif testset[i][-1] == predictions[i]:\n",
    "# \t\t\tcorrect += 1\n",
    "# \treturn (correct/float(len(testset))) * 100.0\n",
    " \n",
    "# def main():\n",
    "# \t\tmsg=pd.read_csv('data.csv',names=['message','label'])\n",
    "# \t\tmsg['labelnum']=msg.label.map({'pos':1,'neg':0})\n",
    "# \t\tX=msg.message\n",
    "# \t\tY=list(msg.label)\n",
    "# \t\tprint(list(Y))\n",
    "# \t\tvectorizer = CountVectorizer()\n",
    "# \t\tmatrix = vectorizer.fit_transform(X)\n",
    "# \t\tfilename = 'naviedata.csv'\n",
    "# \t\tsplitratio = 0.67\n",
    "# \t\tdf = pd.DataFrame(data=matrix.toarray(),columns = vectorizer.get_feature_names())\n",
    "\t\t\n",
    "# \t\tdf[\"result\"]=Y\n",
    "# \t\tdataset=df.values.tolist()\n",
    "# \t\tdataset=loadcsv(dataset)\n",
    "# \t\ttrainingset, testset = splitdataset(dataset, splitratio) \n",
    "# \t\tprint('Split {0} rows into train={1} and test={2} rows'.format(len(dataset), len(trainingset), len(testset)))\n",
    "# \t\t# prepare model\n",
    "# \t\tsummaries = summarizebyclass(trainingset);    \n",
    "# \t\t#print(summaries)\n",
    "# \t\t\t# test model\n",
    "# \t\tpredictions = getpredictions(summaries, testset) #find the predictions of test data with the training data\n",
    "# \t\taccuracy = getaccuracy(testset, predictions)\n",
    "# \t\tprint('Accuracy of the classifier is : {0}%'.format(accuracy),\"\\n\",dataset)\n",
    "  \n",
    " \n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmqaxeCjKY5I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Zo4Kxmz_c7PE",
    "lgduEgoLchhU",
    "oUoRvESpcvPT"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
